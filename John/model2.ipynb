{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "splits Train.csv into x and y for training and validation, each.\n",
    "optionally loads Test.csv into x_test\n",
    "\n",
    "test_preprocess is a functor which is called on the training data before being split up\n",
    "'''\n",
    "def load_data_dict(validation_portion = 1/3, get_test = False):\n",
    "    script_dir = os.path.abspath('')\n",
    "    train_csv_path = os.path.join(script_dir, \"..\", \"data\", \"Train.csv\")\n",
    "    train_csv = np.genfromtxt(train_csv_path, delimiter=',', skip_header=True)\n",
    "    if get_test:\n",
    "        test_csv_path = os.path.join(script_dir, \"..\", \"data\", \"Test.csv\")\n",
    "        test_csv = np.genfromtxt(test_csv_path, delimiter=',', skip_header=True)\n",
    "\n",
    "    data_dict = {}\n",
    "    x_train = train_csv[:,:-1]\n",
    "    y_train = train_csv[:,-1:].transpose()[0]\n",
    "    data_dict['x_train'], data_dict['x_val'] = train_test_split(x_train, test_size=validation_portion)\n",
    "    data_dict['y_train'], data_dict['y_val'] = train_test_split(y_train, test_size=validation_portion)\n",
    "    if get_test:\n",
    "        data_dict['x_test'] = test_csv\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "data_dict = load_data_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator(y_test, y_pred, n=2, all=True):\n",
    "    # both are arrays with values from 0-n\n",
    "    confusion_matrix = np.zeros((n, n), dtype=np.int)\n",
    "    for test, pred in zip(y_test, y_pred):\n",
    "        # matrix is row major, and predicted values are each column\n",
    "        confusion_matrix[int(test)][int(pred)] += 1\n",
    "    print(\"confusion matrix:\\n\" + str(confusion_matrix))\n",
    "\n",
    "    if all:\n",
    "        accuracy = confusion_matrix.trace() / confusion_matrix.sum() # correct / all\n",
    "        print(\"accuracy: %f\" % accuracy)\n",
    "\n",
    "        # true positive / total positive\n",
    "        precision = np.empty((n))\n",
    "        for i in range(n):\n",
    "            sum_positive = 0\n",
    "            for j in range(n):\n",
    "                sum_positive += confusion_matrix[j][i]\n",
    "            precision[i] = confusion_matrix[i][i] / sum_positive\n",
    "        print(\"precision:\\n\" + str(precision))\n",
    "\n",
    "        # true positive / total positive\n",
    "        recall = np.empty((n))\n",
    "        for i in range(n):\n",
    "            recall[i] = confusion_matrix[i][i] / confusion_matrix[i].sum()\n",
    "        print(\"recall:\\n\" + str(recall))\n",
    "\n",
    "        f1 = np.empty((n))\n",
    "        for i in range(n):\n",
    "            f1[i] = (2 * precision[i] * recall[i]) / (precision[i] + recall[i])\n",
    "        print(\"f1:\\n\" + str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "attempt = 2 # [0, 3]\n",
    "\n",
    "if attempt == 0:\n",
    "    model = svm.SVC()\n",
    "    model.fit(data_dict['x_train'], data_dict['y_train'])\n",
    "elif attempt == 1:\n",
    "    model = svm.SVC()\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "    rus = RandomUnderSampler()\n",
    "    data_dict['x_train_reduced'], data_dict['y_train_reduced'] = rus.fit_resample(data_dict['x_train'], data_dict['y_train'])\n",
    "    model.fit(data_dict['x_train_reduced'], data_dict['y_train_reduced'])\n",
    "elif attempt == 2:\n",
    "    model = svm.SVC(kernel='linear')\n",
    "    model.fit(data_dict['x_train'], data_dict['y_train'])\n",
    "elif attempt == 3:\n",
    "    model = svm.SVC(kernel='sigmoid')\n",
    "    model.fit(data_dict['x_train'], data_dict['y_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      "[[513  23]\n",
      " [ 51   1]]\n",
      "accuracy: 0.874150\n",
      "precision:\n",
      "[0.90957447 0.04166667]\n",
      "recall:\n",
      "[0.95708955 0.01923077]\n",
      "f1:\n",
      "[0.93272727 0.02631579]\n"
     ]
    }
   ],
   "source": [
    "data_dict['y_pred'] = model.predict(data_dict['x_val'])\n",
    "evaluator(data_dict['y_val'], data_dict['y_pred'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
